import sys
import cv2
import os
import numpy as np
from detection.detector import YOLOv8Detector
from PyQt6.QtCore import QDateTime
from PyQt6.QtWidgets import QMessageBox  # ðŸ‘ˆ åŠ åˆ°é¡¶éƒ¨ if æ²¡æœ‰
from PyQt6.QtMultimedia import QSoundEffect
from PyQt6.QtCore import QUrl
from PyQt6.QtWidgets import QComboBox  # âœ… æ·»åŠ æ¨¡åž‹é€‰æ‹©ä¸‹æ‹‰æ¡†ç»„ä»¶
from managers.sound_manager import SoundManager
from managers.alert_manager import AlertManager
from managers.log_manager import LogManager
from ui.log_viewer import LogViewerWindow
from PyQt6.QtCore import QTimer  # è®°å¾—é¡¶éƒ¨ import
from PyQt6.QtCore import pyqtSignal
from detection.collision_checker import CollisionChecker  # âœ… åŠ å…¥ç¢°æ’žæ£€æµ‹æ¨¡å—
from detection.detector import YOLOv8Detector, YOLOv8PoseDetector
from utils.config import KEYPOINT_COLOR





from PyQt6.QtWidgets import (
    QApplication, QWidget, QLabel, QPushButton, QVBoxLayout,
    QHBoxLayout, QTableWidget, QTableWidgetItem, QSlider, QStatusBar, QFileDialog
)
from PyQt6.QtGui import QPixmap, QImage
from PyQt6.QtCore import Qt, QThread, pyqtSignal


class VideoThread(QThread):
    frame_update = pyqtSignal(QImage)  # å‘é€å¤„ç†åŽçš„è§†é¢‘å¸§
    detection_result = pyqtSignal(list)  # ðŸ‘ˆ ç”¨äºŽå‘é€æ£€æµ‹ä¿¡æ¯

    def __init__(self):
        super().__init__()
        self.cap = None
        self.running = False
        self.video_source = 0  # é»˜è®¤ä½¿ç”¨æ‘„åƒå¤´
        self.video_writer = None  # ðŸŽ¥ è§†é¢‘å†™å…¥å™¨
        self.detector = YOLOv8Detector(model_path="models/yolo_weights/yolov8n.pt", conf_threshold=0.5)

    def set_video_source(self, source):
        """ è®¾ç½®è§†é¢‘æ¥æºï¼ˆæ‘„åƒå¤´ / æœ¬åœ°è§†é¢‘ï¼‰ """
        self.video_source = source

    def run(self):
        self.cap = cv2.VideoCapture(self.video_source)

        # Step 1ï¼šç¡®ä¿è§†é¢‘æˆåŠŸæ‰“å¼€
        if not self.cap.isOpened():
            print("âŒ è§†é¢‘æ— æ³•æ‰“å¼€ï¼")
            return

        # ðŸŽ¥ è®¾ç½®è§†é¢‘ä¿å­˜å‚æ•°ï¼ˆç¡®ä¿æ”¾åœ¨ cap æˆåŠŸæ‰“å¼€ä¹‹åŽï¼‰
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = self.cap.get(cv2.CAP_PROP_FPS)
        width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.video_writer = cv2.VideoWriter("output_pose.mp4", fourcc, fps, (width, height))

        print("ðŸŽ¥ è§†é¢‘æµå¼€å§‹è¯»å–...")
        print(f"ðŸŽ¯ å½“å‰æ£€æµ‹å™¨ç±»åž‹: {type(self.detector).__name__}")

        try:
            while self.running and self.cap is not None and self.cap.isOpened():
                ret, frame = self.cap.read()

                # Step 2ï¼šè¯»å–å¤±è´¥å°±è·³è¿‡
                if not ret or frame is None or frame.size == 0:
                    print("âš ï¸ è¯»å–ç©ºå¸§ï¼Œè·³è¿‡...")
                    if isinstance(self.video_source, str):  # æ˜¯æœ¬åœ°è§†é¢‘
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # å›žåˆ°é¦–å¸§
                        continue
                    else:
                        break

                # Step 3ï¼šæ£€æµ‹
                if isinstance(self.detector, YOLOv8PoseDetector):
                    detections, keypoints_all = self.detector.detect(frame)
                else:
                    detections = self.detector.detect(frame)

                # Step 4ï¼šç”»æ¡† & ç”»å…³é”®ç‚¹ï¼ˆå¦‚æžœæœ‰ï¼‰
                for det in detections:
                    x1, y1, x2, y2 = map(int, det["bbox"])
                    conf = det["conf"]
                    label = f"{det['class_name']} {conf:.2f}"
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

                # âœ… å¦‚æžœæ˜¯å§¿æ€æ¨¡åž‹ï¼Œç”»å…³é”®ç‚¹éª¨æž¶
                if isinstance(self.detector,YOLOv8PoseDetector) and keypoints_all is not None and keypoints_all.size > 0:
                    self.draw_keypoints(frame, keypoints_all)

                # Step 5ï¼šè½¬æ¢æˆ QImageï¼ˆå¿…é¡»é˜²æ­¢ frame ä¸º Noneï¼‰
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = frame_rgb.shape

                qimg = QImage(frame_rgb.data, w, h, ch * w, QImage.Format.Format_RGB888).copy()

                if self.video_writer:
                    self.video_writer.write(frame)

                self.frame_update.emit(qimg)
                self.detection_result.emit(detections)

        except Exception as e:
            print(f"âŒ è§†é¢‘çº¿ç¨‹å¼‚å¸¸: {e}")


        finally:
            if self.cap:
                self.cap.release()
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None  # æ¸…ç†
                self.cap = None  # é˜²æ­¢å¤–éƒ¨å†è¯¯ç”¨
                print("ðŸ“¤ è§†é¢‘èµ„æºå·²é‡Šæ”¾")

    def draw_keypoints(self, frame, keypoints_all):
        SKELETON = [
            (5, 7), (7, 9), (6, 8), (8, 10),
            (11, 13), (13, 15), (12, 14), (14, 16),
            (5, 6), (11, 12), (5, 11), (6, 12)
        ]

        for keypoints in keypoints_all:
            keypoints = keypoints.tolist()  # âœ… numpy è½¬ list æ›´å®‰å…¨

        for keypoints in keypoints_all:
            # âœ… ç”»å…³é”®ç‚¹
            for keypoints in keypoints_all:
                keypoints = keypoints.tolist()  # ä¿è¯ keypoints æ˜¯ list è€Œä¸æ˜¯ numpy
                for point in keypoints:
                    if len(point) >= 2:
                        x, y = point[:2]
                        cv2.circle(frame, (int(x), int(y)), 3, KEYPOINT_COLOR, -1)

            # âœ… ç”»éª¨æž¶è¿žæŽ¥çº¿
            for i, j in SKELETON:
                if i < len(keypoints) and j < len(keypoints):
                    pt1 = tuple(map(int, keypoints[i][:2]))
                    pt2 = tuple(map(int, keypoints[j][:2]))
                    cv2.line(frame, pt1, pt2, (255, 0, 0), 2)

    def stop(self):
        print("ðŸ›‘ æ­£åœ¨åœæ­¢è§†é¢‘çº¿ç¨‹...")
        self.running = False  # å‘Šè¯‰ run() å¾ªçŽ¯é€€å‡º
        self.wait()  # ç­‰å¾…çº¿ç¨‹è‡ªç„¶ç»“æŸ
        print("âœ… è§†é¢‘çº¿ç¨‹å·²å®‰å…¨é€€å‡º")


class PedestrianDetectionUI(QWidget):

    trigger_alert_signal = pyqtSignal(list)  # âœ… æ–°å¢žï¼šä¸»çº¿ç¨‹ä¸­è§¦å‘æŠ¥è­¦
    def __init__(self):
        super().__init__()
        self.initUI()
        self.video_thread = VideoThread()
        self.video_thread.frame_update.connect(self.update_video_frame)
        self.video_thread.detection_result.connect(self.update_detection_table)

        self.trigger_alert_signal.connect(self.trigger_alert)  # âœ… ä¿¡å·è¿žæŽ¥ trigger_alert



        self.sound_manager = SoundManager()  # âœ… åˆå§‹åŒ–å£°éŸ³æ¨¡å—
        self.alert_manager = AlertManager(self)  # âœ… æ³¨å…¥å½“å‰çª—å£å¼•ç”¨
        self.log_manager = LogManager()  # âœ… åˆå§‹åŒ–æ—¥å¿—æ¨¡å—

        # æ·»åŠ è¿™ä¸€è¡Œï¼š
        self.collision_checker = CollisionChecker(distance_threshold=200)  # é»˜è®¤é˜ˆå€¼ 50ï¼Œå¯è°ƒ

        # æŽ§åˆ¶è­¦æŠ¥åªå¼¹ä¸€æ¬¡ï¼ˆå†·å´æœºåˆ¶ï¼‰
        self.alert_shown = False

        # âœ… æŽ§åˆ¶å°æç¤ºå½“å‰æ¨¡åž‹è·¯å¾„å’Œç±»åˆ«æ˜ å°„
        print(f"[UIåˆå§‹åŒ–] âœ… å½“å‰ä½¿ç”¨æ¨¡åž‹è·¯å¾„: {self.video_thread.detector.model.model.args['model']}")
        print(f"[UIåˆå§‹åŒ–] âœ… å½“å‰æ¨¡åž‹ç±»åˆ«æ˜ å°„: {self.video_thread.detector.class_names}")

    def initUI(self):
        self.setWindowTitle("åŸºäºŽæ·±åº¦å­¦ä¹ çš„è¡Œäººæ£€æµ‹ç³»ç»Ÿ")
        self.setGeometry(100, 100, 900, 600)

        # 1. è§†é¢‘æµæ˜¾ç¤º
        self.video_label = QLabel("è§†é¢‘æµçª—å£", self)
        self.video_label.setStyleSheet("background-color: black; color: white; font-size: 16px;")
        self.video_label.setFixedHeight(300)

        # 2. æŽ§åˆ¶æŒ‰é’®
        self.load_video_btn = QPushButton("åŠ è½½è§†é¢‘")
        self.use_camera_btn = QPushButton("ä½¿ç”¨æ‘„åƒå¤´")
        self.start_detection_btn = QPushButton("å¯åŠ¨æ£€æµ‹")
        self.pause_detection_btn = QPushButton("æš‚åœæ£€æµ‹")
        self.view_logs_btn = QPushButton("æŸ¥çœ‹æ—¥å¿—")
        self.view_statistics_btn = QPushButton("æŸ¥çœ‹ç»Ÿè®¡å›¾")  # æ–°å¢ž
        # âœ… æ¨¡åž‹é€‰æ‹©ä¸‹æ‹‰æ¡†ï¼šyolov8n.pt vs merged_model.pt
        self.model_selector = QComboBox()
        self.model_selector.addItems([
            "åŽŸå§‹æ¨¡åž‹ yolov8n.pt",
            "èžåˆæ¨¡åž‹ merged_model.pt",
            "å§¿æ€æ¨¡åž‹ yolov8x-pose-p6.pt"  # âœ… æ–°å¢ž
        ])
        self.exit_btn = QPushButton("é€€å‡º")

        button_layout = QHBoxLayout()
        button_layout.addWidget(self.load_video_btn)
        button_layout.addWidget(self.use_camera_btn)
        button_layout.addWidget(self.start_detection_btn)
        button_layout.addWidget(self.pause_detection_btn)
        button_layout.addWidget(self.view_logs_btn)  # âœ… æ–°å¢ž
        button_layout.addWidget(self.view_statistics_btn)  # æ–°å¢ž
        button_layout.addWidget(self.model_selector)
        button_layout.addWidget(self.exit_btn)

        # 3. å‚æ•°è°ƒèŠ‚
        self.confidence_slider = QSlider(Qt.Orientation.Horizontal)
        self.confidence_slider.setMinimum(30)
        self.confidence_slider.setMaximum(100)
        self.confidence_slider.setValue(50)
        self.confidence_slider_label = QLabel("ç½®ä¿¡åº¦: 0.50", self)

        slider_layout = QHBoxLayout()
        slider_layout.addWidget(QLabel("æ£€æµ‹ç½®ä¿¡åº¦:"))
        slider_layout.addWidget(self.confidence_slider)
        slider_layout.addWidget(self.confidence_slider_label)

        # ðŸ‘‰ æ·»åŠ ç¢°æ’žé˜ˆå€¼æ»‘å—
        self.threshold_slider = QSlider(Qt.Orientation.Horizontal)
        self.threshold_slider.setMinimum(10)
        self.threshold_slider.setMaximum(300)
        self.threshold_slider.setValue(200)  # é»˜è®¤å€¼ï¼Œå»ºè®®å’Œåˆå§‹åŒ– collision_checker çš„å€¼ä¸€è‡´
        self.threshold_slider_label = QLabel("ç¢°æ’žé˜ˆå€¼: 200 åƒç´ ")

        threshold_layout = QHBoxLayout()
        threshold_layout.addWidget(QLabel("ç¢°æ’žé˜ˆå€¼:"))
        threshold_layout.addWidget(self.threshold_slider)
        threshold_layout.addWidget(self.threshold_slider_label)

        self.confidence_slider.valueChanged.connect(self.update_confidence_label)

        # 4. æ£€æµ‹ç»“æžœè¡¨
        self.result_table = QTableWidget(self)
        self.result_table.setColumnCount(4)
        self.result_table.setHorizontalHeaderLabels(["ID", "æ—¶é—´", "è¡ŒäººID", "ç½®ä¿¡åº¦"])
        self.result_table.setRowCount(5)

        # 5. çŠ¶æ€æ 
        self.status_bar = QStatusBar()
        self.status_bar.showMessage("ç³»ç»Ÿå‡†å¤‡å°±ç»ª")

        # æ€»å¸ƒå±€
        layout = QVBoxLayout()
        layout.addWidget(self.video_label)
        layout.addLayout(button_layout)
        layout.addLayout(slider_layout)
        layout.addWidget(self.result_table)
        layout.addWidget(self.status_bar)
        layout.addLayout(threshold_layout)  # âœ… æŠŠé˜ˆå€¼æ»‘å—åŠ å…¥ä¸»ç•Œé¢å¸ƒå±€

        self.threshold_slider.valueChanged.connect(self.update_threshold_label)
        self.setLayout(layout)

        # ç»‘å®šæŒ‰é’®äº‹ä»¶
        self.load_video_btn.clicked.connect(self.load_video)
        self.use_camera_btn.clicked.connect(self.use_camera)
        self.start_detection_btn.clicked.connect(self.start_detection)
        self.pause_detection_btn.clicked.connect(self.pause_detection)
        self.view_logs_btn.clicked.connect(self.view_logs)  # âœ… æ–°å¢ž
        self.view_statistics_btn.clicked.connect(self.view_statistics)
        self.exit_btn.clicked.connect(self.close_app)

    def update_video_frame(self, img):
        self.video_label.setPixmap(QPixmap.fromImage(img))

    def update_confidence_label(self):
        value = self.confidence_slider.value() / 100.0
        self.confidence_slider_label.setText(f"ç½®ä¿¡åº¦: {value:.2f}")
        self.video_thread.detector.set_conf_threshold(value)  # ðŸ‘ˆ å®žæ—¶æ›´æ–°æ£€æµ‹å™¨é˜ˆå€¼

    def update_threshold_label(self):
        value = self.threshold_slider.value()
        self.threshold_slider_label.setText(f"ç¢°æ’žé˜ˆå€¼: {value} åƒç´ ")
        self.collision_checker.threshold = value  # âœ… å®žæ—¶åŒæ­¥åˆ°ç¢°æ’žæ£€æµ‹æ¨¡å—
        print(f"ðŸ“ å®žæ—¶æ›´æ–°ç¢°æ’žé˜ˆå€¼ä¸ºï¼š{value} åƒç´ ")

    def update_detection_table(self, detections):
        self.result_table.setRowCount(len(detections))  # æ ¹æ®æ£€æµ‹æ•°è°ƒæ•´è¡Œæ•°
        for i, det in enumerate(detections):
            self.result_table.setItem(i, 0, QTableWidgetItem(str(i + 1)))
            self.result_table.setItem(i, 1, QTableWidgetItem(QDateTime.currentDateTime().toString("hh:mm:ss")))
            self.result_table.setItem(i, 2, QTableWidgetItem(det["class_name"]))
            self.result_table.setItem(i, 3, QTableWidgetItem(f"{det['conf']:.2f}"))

            # âœ… æ—¥å¿—è®°å½•ï¼šæ¯ä¸€æ¬¡æ£€æµ‹
            self.log_manager.log_detection(det["bbox"], det["conf"], det["class_name"])


        # ðŸš¨ æ¡ä»¶ 1ï¼šç¢°æ’žé¢„è­¦ï¼ˆäººè½¦è·ç¦»è¿‡è¿‘ï¼‰
        # åˆ†ç¦»å‡ºè¡Œäººä¸Žè½¦è¾†ï¼ˆclass_id: 0 = person, 2/5/7 = car/bus/truckï¼‰
        pedestrians = [d for d in detections if d.get("class_id") == 0]
        vehicles = [d for d in detections if d.get("class_id") in [2, 5, 7]]

        # âš ï¸ åˆ¤æ–­äººè½¦æ˜¯å¦æœ‰å¯èƒ½ç¢°æ’žï¼ˆåƒç´ è·ç¦»å°äºŽé˜ˆå€¼ï¼‰
        # âœ… æ­£ç¡®å†™æ³•ï¼ˆä½¿ç”¨ self.collision_checkerï¼‰ï¼š
        collision_risk = self.collision_checker.check(pedestrians, vehicles)

        # âœ… æ–°è§¦å‘é€»è¾‘ï¼šåªæœ‰åœ¨å­˜åœ¨ç¢°æ’žé£Žé™©æ—¶ï¼Œæ‰å‘å‡ºé¢„è­¦
        if collision_risk:
            print("âš ï¸âš ï¸âš ï¸ äººè½¦æŽ¥è¿‘ï¼Œè§¦å‘é¢„è­¦ï¼")
            self.trigger_alert_signal.emit(detections)

        # âœ… æœªæ¥è¿™é‡Œå°†æ˜¯ç¢°æ’žé¢„è­¦ä¸»é€»è¾‘å…¥å£
        # print(f"ðŸš¶ è¡Œäººæ•°é‡: {len(pedestrians)}ï¼ŒðŸš— è½¦è¾†æ•°é‡: {len(vehicles)}")

    def trigger_alert(self, detections):
        if not self.alert_shown:
            self.alert_shown = True

            self.sound_manager.play_alert()  # âœ… æ’­æ”¾å£°éŸ³
            self.alert_manager.show_warning("âš ï¸ å®‰å…¨é¢„è­¦", "æ£€æµ‹åˆ°å¤šäººæˆ–é«˜é£Žé™©ç›®æ ‡ï¼è¯·æ³¨æ„å®‰å…¨ï¼")

            # âœ… æ—¥å¿—è®°å½•ï¼šå–ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ªæŠ¥è­¦
            if detections:
                top_det = max(detections, key=lambda d: d["conf"])

                # ðŸš¶â€â™€ï¸ æŠ½å–è¡Œäººä¸Žè½¦è¾†
                pedestrians = [d for d in detections if d.get("class_id") == 0]
                vehicles = [d for d in detections if d.get("class_id") in [2, 5, 7]]

                # ðŸ§  åˆ¤æ–­æŠ¥è­¦ç±»åž‹
                if self.collision_checker.check(pedestrians, vehicles):
                    event_type = "ç¢°æ’žé¢„è­¦"
                else:
                    event_type = top_det["class_name"]

                # âœ… æ—¥å¿—è®°å½•
                self.log_manager.log_alert(top_det["bbox"], top_det["conf"], event_type)

            # â± è®¾ç½® 5 ç§’åŽè‡ªåŠ¨è§£é”
            QTimer.singleShot(5000, self.reset_alert_flag)

    def reset_alert_flag(self):
        self.alert_shown = False
        print("ðŸŸ¢ è­¦æŠ¥å†·å´ç»“æŸï¼Œå¯ä»¥å†æ¬¡è§¦å‘")

    def load_video(self):
        """ é€‰æ‹©æœ¬åœ°è§†é¢‘æ–‡ä»¶ä½œä¸ºè¾“å…¥ """
        file_path, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi)")
        if file_path:
            self.video_thread.set_video_source(file_path)
            self.status_bar.showMessage(f"å·²åŠ è½½è§†é¢‘: {file_path}")

    def use_camera(self):
        """ åˆ‡æ¢å›žæ‘„åƒå¤´æ¨¡å¼ """
        self.video_thread.set_video_source(0)
        self.status_bar.showMessage("å·²åˆ‡æ¢è‡³æ‘„åƒå¤´æ¨¡å¼")

    def start_detection(self):
        if not self.video_thread.isRunning():
            selected_model = self.model_selector.currentText()

            # 1. å†³å®šæ¨¡åž‹è·¯å¾„
            if "èžåˆ" in selected_model:
                model_path = "models/yolo_weights/merged_model.pt"
            elif "å§¿æ€" in selected_model:
                model_path = "models/yolo_weights/yolov8x-pose-p6.pt"
            else:
                model_path = "models/yolo_weights/yolov8n.pt"

            # 2. å†³å®šä½¿ç”¨å“ªä¸ªç±»
            if "å§¿æ€" in selected_model:
                DetectorClass = YOLOv8PoseDetector
            else:
                DetectorClass = YOLOv8Detector

            # âœ… åªå†™ä¸€æ¬¡å®žä¾‹åŒ–ï¼
            self.video_thread.detector = DetectorClass(
                model_path=model_path,
                conf_threshold=self.confidence_slider.value() / 100.0
            )

            self.video_thread.running = True
            self.video_thread.start()
            self.status_bar.showMessage(f"âœ… ä½¿ç”¨æ¨¡åž‹ï¼š{selected_model}ï¼Œæ£€æµ‹å·²å¯åŠ¨...")

    def pause_detection(self):
        """ æš‚åœæ£€æµ‹ """
        if self.video_thread.isRunning():
            self.video_thread.stop()
            self.status_bar.showMessage("è¡Œäººæ£€æµ‹å·²æš‚åœ")

    def view_logs(self):
        latest_log_path = self.log_manager.get_latest_log_path()
        print(f"ðŸ’¡ èŽ·å–æ—¥å¿—è·¯å¾„: {latest_log_path}")
        if not os.path.exists(latest_log_path):
            QMessageBox.warning(self, "æç¤º", "æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ï¼")
            return

        try:
            self.log_viewer = LogViewerWindow(latest_log_path)
            self.log_viewer.show()
            print("âœ… æ—¥å¿—çª—å£æˆåŠŸå¼¹å‡º")
        except Exception as e:
            print("âŒ å¼¹å‡ºå¤±è´¥:", e)

    def view_statistics(self):
        from ui.log_statistics_window import LogStatisticsWindow
        self.statistics_window = LogStatisticsWindow()
        self.statistics_window.show()

    def close_app(self):
        """ é€€å‡ºåº”ç”¨ """
        self.status_bar.showMessage("æ­£åœ¨é€€å‡º...")
        if self.video_thread.isRunning():
            self.video_thread.stop()
        QApplication.quit()


if __name__ == "__main__":
    app = QApplication(sys.argv)
    win = PedestrianDetectionUI()
    win.show()
    sys.exit(app.exec())
